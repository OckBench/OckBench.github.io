<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="OckBench: The first benchmark measuring decoding token efficiency alongside accuracy for LLM reasoning. Tokens are not to be multiplied without necessity.">
  <meta name="keywords" content="OckBench, LLM, Token Efficiency, Reasoning Benchmark, Ockham's Razor, Decoding Efficiency">
  <title>OckBench: Measuring the Efficiency of LLM Reasoning</title>

  <link rel="icon" href="./static/images/ockbench-logo.svg">

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="stylesheet" href="./static/css/leaderboard.css">

  <script type="text/javascript" src="static/js/sort-table.js" defer></script>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>

  <script src="./static/data/leaderboard_data.js" defer></script>

  <style>
    .no-sort {
        cursor: default;
        pointer-events: none;
        background-image: none !important;
    }
    .ockbench {
      font-weight: bold;
      color: #2563eb;
    }
    .metric-card {
      background: #f8fafc;
      border: 2px solid #e2e8f0;
      border-radius: 8px;
      padding: 20px;
      margin: 10px;
      text-align: center;
    }
    .metric-title {
      font-size: 14px;
      color: #64748b;
      margin-bottom: 8px;
    }
    .metric-value {
      font-size: 32px;
      font-weight: bold;
      color: #2563eb;
    }
  </style>

</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title is-bold">
            <img src="static/images/ockbench-logo.svg" style="width:1.6em;vertical-align: middle" alt="Logo"/>
            <span class="ockbench" style="vertical-align: middle">OckBench</span>
          </h1>
          <h2 class="subtitle is-3 publication-subtitle" style="margin-bottom: 20px;">
            Tokens are Not to Be Multiplied without Necessity
          </h2>
          
          <div class="is-size-5 publication-authors" style="margin: 20px auto;">
            <span class="author-block">
              <a href="#">Zheng Du</a><sup>1*</sup>,
            </span>
            <span class="author-block">
              <a href="#">Hao Kang</a><sup>1*</sup>,
            </span>
            <span class="author-block">
              <a href="#">Song Han</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="#">Tushar Krishna</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="#">Ligeng Zhu</a><sup>3</sup>
            </span>
          </div>
          <div class="is-size-7" style="margin-top: -8px; margin-bottom: 6px;">
            <span><sup>*</sup>Equal contribution</span>
          </div>
          
          <div class="is-size-6 publication-authors" style="margin: 10px auto;">
            <span class="author-block" style="margin-right: 2em;"><sup>1</sup>Georgia Institute of Technology</span>
            <span class="author-block" style="margin-right: 2em;"><sup>2</sup>MIT</span>
            <span class="author-block"><sup>3</sup>NVIDIA</span>
          </div>
          

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- arXiv Link -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2511.05722" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link -->
              <span class="link-block">
                <a href="https://github.com/OckBench/OckBench" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>GitHub</span>
                </a>
              </span>
              <!-- Dataset Link -->
              <span class="link-block">
                <a href="https://huggingface.co/datasets/ockbench/ockbench" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <p style="font-size:18px">ü§ó</p>
                  </span>
                  <span>Dataset</span>
                </a>
              </span>
              <!-- Leaderboard Link -->
              <span class="link-block">
                <a href="#leaderboard" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <p style="font-size:18px">üèÜ</p>
                  </span>
                  <span>Leaderboard</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>



<section class="section">
  <div class="container" style="margin-bottom: 2vh;">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Introduction</h2>
        <div class="content has-text-justified">
          <p style="text-align: center; font-style: italic; margin-bottom: 20px;">
            "Entities must not be multiplied beyond necessity." ‚Äî The Principle of Ockham's Razor
          </p>
          <p>
            Large Language Models (LLMs) like GPT-5, Gemini 3, and Claude serve as the frontier of automated intelligence, fueled by reasoning techniques like Chain of Thought (CoT). As the field embraces test-time compute scaling, models are increasingly trained to generate extensive token chains to tackle tougher problems. However, this massive inflation of decoding tokens introduces a critical bottleneck: solving just six problems in the International Olympiad in Informatics can now take over ten hours, and complex mathematical challenges frequently explode into millions of tokens.
          </p>
          <p>
            While the community celebrates gains in reasoning capability, prevailing benchmarks like HELM and Chatbot Arena focus almost exclusively on output quality, ignoring this <strong>token efficiency crisis</strong>. In reality, many models consume vastly more tokens than necessary to reach the correct answer. Models of identical size (7B) achieving similar accuracy can differ by over <strong>3.4√ó in token consumption</strong> and <strong>5.0√ó in end-to-end latency</strong>. As accuracy on standard tasks approaches saturation, tokens must be treated as a cost ‚Äî not a free resource.
          </p>
          <p>
            We introduce <strong>OckBench</strong>, the first model- and hardware-agnostic benchmark that jointly measures accuracy and token efficiency. Our key contributions include:
          </p>
          <ul style="text-align: left; display: inline-block;">
            <li><strong>Per-Token Intelligence:</strong> We introduce a new evaluation dimension ‚Äî a superior model must not only achieve high accuracy but do so with minimal token consumption</li>
            <li><strong>OckBench &amp; OckScore:</strong> A benchmark with a novel Differentiation Filter that isolates tasks exposing the efficiency gap, paired with a unified metric that rewards high accuracy achieved with fewer tokens</li>
            <li><strong>The Overthinking Tax:</strong> We formally quantify how smaller models often incur paradoxically higher deployment costs due to excessive verbose reasoning chains</li>
            <li><strong>Optimization Pathways:</strong> We demonstrate that efficiency is tractable ‚Äî both training-free model interpolation and difficulty-aware RL significantly improve OckScore</li>
          </ul>
          <p>
            Through extensive evaluations on 47 frontier and open-source models, we find that top open-source models have nearly closed the accuracy gap but consume up to <strong>5.1√ó more tokens</strong> than commercial counterparts for comparable accuracy. Meanwhile, frontier commercial models are rapidly co-optimizing both dimensions, validating Per-Token Intelligence as the next key axis of LLM evaluation.
          </p>
          
          <!-- Bubble Plot: Hero Figure -->
          <div style="margin-top: 40px;">
            <figure style="text-align: center;">
              <img src="static/images/bubble_plot.png" alt="Accuracy vs. Token Consumption for all 47 evaluated models" style="width: 90%; max-width: 900px; height: auto; border-radius: 10px; box-shadow: 0 4px 20px rgba(0,0,0,0.12);">
              <figcaption style="margin-top: 12px; font-size: 14px; color: #64748b; max-width: 750px; margin-left: auto; margin-right: auto;">
                Accuracy vs. Average Tokens across 47 evaluated models. Models in the upper-left corner are ideal. The Pareto frontier is dominated by commercial models; open-source models cluster to the right.
              </figcaption>
            </figure>
          </div>

          <!-- Three Key Observations -->
          <div class="columns is-centered" style="margin-top: 50px;">
            <div class="column is-one-third" style="padding: 12px 16px;">
              <figure style="text-align: center;">
                <img src="static/images/performance_comparison_7b_modified.png" alt="7B models: AceReason-7B is 5x faster than DeepSeek-R1-7B at same parameter scale" style="width: 100%; height: 260px; object-fit: contain; border-radius: 8px; background: #fafafa;">
                <figcaption style="margin-top: 10px; font-size: 13px; color: #64748b;">
                  <strong>Same Scale, 5√ó Faster.</strong> At identical 7B parameters, AceReason-7B is 5.0√ó faster than DeepSeek-R1-7B by using 3.4√ó fewer tokens.
                </figcaption>
              </figure>
            </div>
            <div class="column is-one-third" style="padding: 12px 16px;">
              <figure style="text-align: center;">
                <img src="static/images/deepseek_vs_gpt_comparison.png" alt="Open vs Closed Source: DeepSeek-V3.2 uses 5.1x more tokens than GPT-5.2 at similar accuracy" style="width: 100%; height: 260px; object-fit: contain; border-radius: 8px; background: #fafafa;">
                <figcaption style="margin-top: 10px; font-size: 13px; color: #64748b;">
                  <strong>Open vs. Closed Gap.</strong> DeepSeek-V3.2 matches GPT-5.2 in accuracy but consumes 5.1√ó more tokens ‚Äî open-source lags in per-token intelligence.
                </figcaption>
              </figure>
            </div>
            <div class="column is-one-third" style="padding: 12px 16px;">
              <figure style="text-align: center;">
                <img src="static/images/qwen3_series_comparison.png" alt="The Overthinking Tax: larger Qwen3 models use fewer tokens than smaller ones" style="width: 100%; height: 260px; object-fit: contain; border-radius: 8px; background: #fafafa;">
                <figcaption style="margin-top: 10px; font-size: 13px; color: #64748b;">
                  <strong>The Overthinking Tax.</strong> In the Qwen3 family, larger models are paradoxically <em>more</em> token-efficient ‚Äî smaller models over-generate to compensate for lower capacity.
                </figcaption>
              </figure>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-full has-text-centered content">
        <h2 class="title is-3" id="leaderboard">Leaderboard</h2>
        <div class="content">
          <p class="mt-3">
            Performance of various LLMs on <strong>OckBench-Math</strong> (200 questions). Models are ranked by <strong>OckScore</strong> = Accuracy ‚àí 10 √ó log(Tokens / 10,000) ‚Äî higher is better. All models evaluated with single-shot prompts and greedy decoding (temperature = 0).
          </p>
          <!-- <p style="font-size: 14px; color: #64748b;">
            <strong>#Tokens:</strong> Average decoding token count &nbsp;&nbsp;
            <strong>Accuracy (%):</strong> Percentage of correctly solved problems &nbsp;&nbsp;
            <strong>Reasoning Efficiency:</strong> #Tokens / Accuracy (lower is better)
          </p> -->
        </div>

        <!-- Domain Tabs -->
        <div class="tabs is-centered is-boxed" style="margin-top: 20px;">
          <ul>
            <li class="is-active" data-tab="math">
              <a>
                <span class="icon is-small"><i class="fas fa-calculator"></i></span>
                <span>OckBench-Math</span>
              </a>
            </li>
            <!-- Coding tab hidden until results are ready
            <li data-tab="coding">
              <a>
                <span class="icon is-small"><i class="fas fa-code"></i></span>
                <span>OckBench-Coding</span>
              </a>
            </li>
            -->
          </ul>
        </div>

        <!-- Math Leaderboard -->
        <div id="math-table" class="leaderboard-table">
          <table class="js-sort-table" id="results-math" style="margin-left: auto; margin-right: auto; margin-top: 20px;">
            <thead>
              <tr>
                <th class="no-sort" style="vertical-align: middle; width: 50px;"><strong>#</strong></th>
                <th class="no-sort" style="vertical-align: middle; width: 250px;"><strong>Model</strong></th>
                <th class="no-sort" style="vertical-align: middle; width: 100px;"><strong>License</strong></th>
                <th data-js-sort-colNum="3" style="vertical-align: middle; width: 120px;"><strong>Avg Tokens</strong></th>
                <th data-js-sort-colNum="4" style="vertical-align: middle; width: 120px;"><strong>Accuracy (%)</strong></th>
                <th data-js-sort-colNum="5" style="vertical-align: middle; width: 160px;"><strong>OckScore ‚Üë</strong></th>
              </tr>
            </thead>
            <tbody>
              <tr><td>1</td><td style="text-align: left; padding-left: 10px;"><b>gemini-3.1-pro-preview</b><br><span style="font-size: 12px; color: #858383;">Gemini</span></td><td>Commercial</td><td>24,765</td><td>75.5</td><td>70.09</td></tr>
              <tr><td>2</td><td style="text-align: left; padding-left: 10px;"><b>gemini-3-pro-preview</b><br><span style="font-size: 12px; color: #858383;">Gemini</span></td><td>Commercial</td><td>20,154</td><td>72.0</td><td>67.21</td></tr>
              <tr><td>3</td><td style="text-align: left; padding-left: 10px;"><b>gemini-3-flash-preview</b><br><span style="font-size: 12px; color: #858383;">Gemini</span></td><td>Commercial</td><td>36,212</td><td>71.0</td><td>64.35</td></tr>
              <tr><td>4</td><td style="text-align: left; padding-left: 10px;"><b>Qwen3.5-397B-A17B-FP8</b><br><span style="font-size: 12px; color: #858383;">Qwen</span></td><td>Open-Source</td><td>33,994</td><td>68.5</td><td>62.07</td></tr>
              <tr><td>5</td><td style="text-align: left; padding-left: 10px;"><b>gpt-5.2 (high)</b><br><span style="font-size: 12px; color: #858383;">OpenAI</span></td><td>Commercial</td><td>19,541</td><td>66.0</td><td>61.30</td></tr>
              <tr><td>6</td><td style="text-align: left; padding-left: 10px;"><b>gpt-5.2 (medium)</b><br><span style="font-size: 12px; color: #858383;">OpenAI</span></td><td>Commercial</td><td>15,683</td><td>63.0</td><td>58.90</td></tr>
              <tr><td>7</td><td style="text-align: left; padding-left: 10px;"><b>gpt-5-mini (high)</b><br><span style="font-size: 12px; color: #858383;">OpenAI</span></td><td>Commercial</td><td>29,297</td><td>52.0</td><td>46.06</td></tr>
              <tr><td>8</td><td style="text-align: left; padding-left: 10px;"><b>Kimi-K2-Thinking</b><br><span style="font-size: 12px; color: #858383;">Kimi</span></td><td>Open-Source</td><td>41,746</td><td>52.5</td><td>45.36</td></tr>
              <tr><td>9</td><td style="text-align: left; padding-left: 10px;"><b>gpt-5.2 (low)</b><br><span style="font-size: 12px; color: #858383;">OpenAI</span></td><td>Commercial</td><td>5,003</td><td>41.5</td><td>39.74</td></tr>
              <tr><td>10</td><td style="text-align: left; padding-left: 10px;"><b>DeepSeek-V3.2-Thinking</b><br><span style="font-size: 12px; color: #858383;">DeepSeek</span></td><td>Open-Source</td><td>25,492</td><td>43.5</td><td>38.00</td></tr>
              <tr><td>11</td><td style="text-align: left; padding-left: 10px;"><b>o4-mini (high)</b><br><span style="font-size: 12px; color: #858383;">OpenAI</span></td><td>Commercial</td><td>25,677</td><td>43.5</td><td>37.98</td></tr>
              <tr><td>12</td><td style="text-align: left; padding-left: 10px;"><b>gpt-5-mini (medium)</b><br><span style="font-size: 12px; color: #858383;">OpenAI</span></td><td>Commercial</td><td>8,831</td><td>38.5</td><td>35.75</td></tr>
              <tr><td>13</td><td style="text-align: left; padding-left: 10px;"><b>gemini-2.5-pro</b><br><span style="font-size: 12px; color: #858383;">Gemini</span></td><td>Commercial</td><td>30,622</td><td>41.0</td><td>34.91</td></tr>
              <tr><td>14</td><td style="text-align: left; padding-left: 10px;"><b>o4-mini (medium)</b><br><span style="font-size: 12px; color: #858383;">OpenAI</span></td><td>Commercial</td><td>6,514</td><td>36.0</td><td>33.82</td></tr>
              <tr><td>15</td><td style="text-align: left; padding-left: 10px;"><b>Qwen3-235B-A22B-Thinking-2507</b><br><span style="font-size: 12px; color: #858383;">Qwen</span></td><td>Open-Source</td><td>28,558</td><td>38.5</td><td>32.64</td></tr>
              <tr><td>16</td><td style="text-align: left; padding-left: 10px;"><b>o3-mini (high)</b><br><span style="font-size: 12px; color: #858383;">OpenAI</span></td><td>Commercial</td><td>21,623</td><td>37.0</td><td>32.00</td></tr>
              <tr><td>17</td><td style="text-align: left; padding-left: 10px;"><b>Qwen3-30B-A3B-Thinking-2507</b><br><span style="font-size: 12px; color: #858383;">Qwen</span></td><td>Open-Source</td><td>30,513</td><td>37.0</td><td>30.92</td></tr>
              <tr><td>18</td><td style="text-align: left; padding-left: 10px;"><b>Qwen3-32B-Thinking</b><br><span style="font-size: 12px; color: #858383;">Qwen</span></td><td>Open-Source</td><td>19,098</td><td>31.0</td><td>26.36</td></tr>
              <tr><td>19</td><td style="text-align: left; padding-left: 10px;"><b>o3-mini (medium)</b><br><span style="font-size: 12px; color: #858383;">OpenAI</span></td><td>Commercial</td><td>7,251</td><td>27.5</td><td>25.13</td></tr>
              <tr><td>20</td><td style="text-align: left; padding-left: 10px;"><b>Qwen3-235B-A22B-Instruct-2507</b><br><span style="font-size: 12px; color: #858383;">Qwen</span></td><td>Open-Source</td><td>7,707</td><td>27.0</td><td>24.52</td></tr>
              <tr><td>21</td><td style="text-align: left; padding-left: 10px;"><b>DeepSeek-R1</b><br><span style="font-size: 12px; color: #858383;">DeepSeek</span></td><td>Open-Source</td><td>24,685</td><td>28.5</td><td>23.10</td></tr>
              <tr><td>22</td><td style="text-align: left; padding-left: 10px;"><b>AReaL-boba-2-32B</b><br><span style="font-size: 12px; color: #858383;">AReaL</span></td><td>Open-Source</td><td>23,327</td><td>27.0</td><td>21.77</td></tr>
              <tr><td>23</td><td style="text-align: left; padding-left: 10px;"><b>AceReason-Nemotron-14B</b><br><span style="font-size: 12px; color: #858383;">AceReason</span></td><td>Open-Source</td><td>19,424</td><td>25.0</td><td>20.31</td></tr>
              <tr><td>24</td><td style="text-align: left; padding-left: 10px;"><b>AReaL-boba-2-14B</b><br><span style="font-size: 12px; color: #858383;">AReaL</span></td><td>Open-Source</td><td>21,309</td><td>25.0</td><td>20.04</td></tr>
              <tr><td>25</td><td style="text-align: left; padding-left: 10px;"><b>gpt-5-mini (low)</b><br><span style="font-size: 12px; color: #858383;">OpenAI</span></td><td>Commercial</td><td>2,148</td><td>20.5</td><td>19.65</td></tr>
              <tr><td>26</td><td style="text-align: left; padding-left: 10px;"><b>DeepSeek-V3.2-Instruct</b><br><span style="font-size: 12px; color: #858383;">DeepSeek</span></td><td>Open-Source</td><td>9,379</td><td>21.0</td><td>18.13</td></tr>
              <tr><td>27</td><td style="text-align: left; padding-left: 10px;"><b>o3-mini (low)</b><br><span style="font-size: 12px; color: #858383;">OpenAI</span></td><td>Commercial</td><td>1,898</td><td>18.5</td><td>17.75</td></tr>
              <tr><td>28</td><td style="text-align: left; padding-left: 10px;"><b>Kimi-K2-Instruct-0905</b><br><span style="font-size: 12px; color: #858383;">Kimi</span></td><td>Open-Source</td><td>3,823</td><td>18.5</td><td>17.09</td></tr>
              <tr><td>29</td><td style="text-align: left; padding-left: 10px;"><b>AceReason-Nemotron-7B</b><br><span style="font-size: 12px; color: #858383;">AceReason</span></td><td>Open-Source</td><td>12,315</td><td>20.5</td><td>17.01</td></tr>
              <tr><td>30</td><td style="text-align: left; padding-left: 10px;"><b>o4-mini (low)</b><br><span style="font-size: 12px; color: #858383;">OpenAI</span></td><td>Commercial</td><td>2,022</td><td>17.5</td><td>16.70</td></tr>
              <tr><td>31</td><td style="text-align: left; padding-left: 10px;"><b>Qwen3-14B-Thinking</b><br><span style="font-size: 12px; color: #858383;">Qwen</span></td><td>Open-Source</td><td>19,381</td><td>21.0</td><td>16.32</td></tr>
              <tr><td>32</td><td style="text-align: left; padding-left: 10px;"><b>Qwen3-4B-Thinking-2507</b><br><span style="font-size: 12px; color: #858383;">Qwen</span></td><td>Open-Source</td><td>27,238</td><td>22.0</td><td>16.29</td></tr>
              <tr><td>33</td><td style="text-align: left; padding-left: 10px;"><b>Qwen3-30B-A3B-Instruct-2507</b><br><span style="font-size: 12px; color: #858383;">Qwen</span></td><td>Open-Source</td><td>12,475</td><td>18.5</td><td>14.98</td></tr>
              <tr><td>34</td><td style="text-align: left; padding-left: 10px;"><b>AReaL-boba-2-8B</b><br><span style="font-size: 12px; color: #858383;">AReaL</span></td><td>Open-Source</td><td>24,127</td><td>20.0</td><td>14.67</td></tr>
              <tr><td>35</td><td style="text-align: left; padding-left: 10px;"><b>DeepSeek-R1-Distill-Qwen-32B</b><br><span style="font-size: 12px; color: #858383;">DeepSeek</span></td><td>Open-Source</td><td>12,895</td><td>15.5</td><td>11.90</td></tr>
              <tr><td>36</td><td style="text-align: left; padding-left: 10px;"><b>DeepSeek-R1-Distill-Qwen-14B</b><br><span style="font-size: 12px; color: #858383;">DeepSeek</span></td><td>Open-Source</td><td>13,211</td><td>15.0</td><td>11.34</td></tr>
              <tr><td>37</td><td style="text-align: left; padding-left: 10px;"><b>Qwen3-8B-Thinking</b><br><span style="font-size: 12px; color: #858383;">Qwen</span></td><td>Open-Source</td><td>24,207</td><td>16.5</td><td>11.16</td></tr>
              <tr><td>38</td><td style="text-align: left; padding-left: 10px;"><b>Qwen3-4B-Instruct-2507</b><br><span style="font-size: 12px; color: #858383;">Qwen</span></td><td>Open-Source</td><td>11,859</td><td>13.5</td><td>10.10</td></tr>
              <tr><td>39</td><td style="text-align: left; padding-left: 10px;"><b>Qwen3-14B-Instruct</b><br><span style="font-size: 12px; color: #858383;">Qwen</span></td><td>Open-Source</td><td>8,205</td><td>10.0</td><td>7.40</td></tr>
              <tr><td>40</td><td style="text-align: left; padding-left: 10px;"><b>DeepSeek-R1-Distill-Qwen-7B</b><br><span style="font-size: 12px; color: #858383;">DeepSeek</span></td><td>Open-Source</td><td>41,415</td><td>14.5</td><td>7.39</td></tr>
              <tr><td>41</td><td style="text-align: left; padding-left: 10px;"><b>gpt-4.1</b><br><span style="font-size: 12px; color: #858383;">OpenAI</span></td><td>Commercial</td><td>4,668</td><td>8.5</td><td>6.84</td></tr>
              <tr><td>42</td><td style="text-align: left; padding-left: 10px;"><b>gemini-2.5-flash</b><br><span style="font-size: 12px; color: #858383;">Gemini</span></td><td>Commercial</td><td>59,447</td><td>13.0</td><td>4.58</td></tr>
              <tr><td>43</td><td style="text-align: left; padding-left: 10px;"><b>Qwen3-8B-Instruct</b><br><span style="font-size: 12px; color: #858383;">Qwen</span></td><td>Open-Source</td><td>10,655</td><td>7.5</td><td>4.35</td></tr>
              <tr><td>44</td><td style="text-align: left; padding-left: 10px;"><b>Qwen3-32B-Instruct</b><br><span style="font-size: 12px; color: #858383;">Qwen</span></td><td>Open-Source</td><td>9,233</td><td>6.0</td><td>3.16</td></tr>
              <tr><td>45</td><td style="text-align: left; padding-left: 10px;"><b>gpt-4o</b><br><span style="font-size: 12px; color: #858383;">OpenAI</span></td><td>Commercial</td><td>947</td><td>3.5</td><td>3.11</td></tr>
              <tr><td>46</td><td style="text-align: left; padding-left: 10px;"><b>gemini-2.5-flash-lite</b><br><span style="font-size: 12px; color: #858383;">Gemini</span></td><td>Commercial</td><td>61,040</td><td>1.0</td><td>-7.52</td></tr>
            </tbody>
          </table>
        </div>

        <!-- Coding Leaderboard -->
        <div id="coding-table" class="leaderboard-table" style="display: none;">
          <table class="js-sort-table" id="results-coding" style="margin-left: auto; margin-right: auto; margin-top: 20px;">
            <thead>
              <tr>
                <th class="no-sort" style="vertical-align: middle; width: 50px;"><strong>#</strong></th>
                <th class="no-sort" style="vertical-align: middle; width: 250px;"><strong>Model</strong></th>
                <th class="no-sort" style="vertical-align: middle; width: 100px;"><strong>Category</strong></th>
                <th data-js-sort-colNum="3" style="vertical-align: middle; width: 120px;"><strong>#Tokens</strong></th>
                <th data-js-sort-colNum="4" style="vertical-align: middle; width: 120px;"><strong>Accuracy (%)</strong></th>
                <th data-js-sort-colNum="5" style="vertical-align: middle; width: 150px;"><strong>Reasoning Efficiency</strong></th>
              </tr>
            </thead>
            <tbody>
              <tr><td>1</td><td style="text-align: left; padding-left: 10px;"><b>Qwen3-235B-A22B (non-thinking)</b><br><span style="font-size: 12px; color: #858383;">Alibaba</span></td><td>Open-Source</td><td>519.31</td><td>61.00</td><td>851.3</td></tr>
              <tr><td>2</td><td style="text-align: left; padding-left: 10px;"><b>gpt-4.1</b><br><span style="font-size: 12px; color: #858383;">OpenAI</span></td><td>Commercial</td><td>639.80</td><td>74.50</td><td>858.1</td></tr>
              <tr><td>3</td><td style="text-align: left; padding-left: 10px;"><b>Qwen3-32B (non-thinking)</b><br><span style="font-size: 12px; color: #858383;">Alibaba</span></td><td>Open-Source</td><td>493.23</td><td>53.50</td><td>921.9</td></tr>
              <tr><td>4</td><td style="text-align: left; padding-left: 10px;"><b>gpt-4o</b><br><span style="font-size: 12px; color: #858383;">OpenAI</span></td><td>Commercial</td><td>573.54</td><td>61.50</td><td>932.6</td></tr>
              <tr><td>5</td><td style="text-align: left; padding-left: 10px;"><b>Qwen3-30B-A3B (non-thinking)</b><br><span style="font-size: 12px; color: #858383;">Alibaba</span></td><td>Open-Source</td><td>631.42</td><td>54.00</td><td>1,169.3</td></tr>
              <tr><td>6</td><td style="text-align: left; padding-left: 10px;"><b>gpt-5</b><br><span style="font-size: 12px; color: #858383;">OpenAI</span></td><td>Commercial</td><td>1,584.41</td><td>96.50</td><td>1,641.8</td></tr>
              <tr><td>7</td><td style="text-align: left; padding-left: 10px;"><b>Qwen3-14B (non-thinking)</b><br><span style="font-size: 12px; color: #858383;">Alibaba</span></td><td>Open-Source</td><td>990.27</td><td>51.00</td><td>1,941.7</td></tr>
              <tr><td>8</td><td style="text-align: left; padding-left: 10px;"><b>Qwen/Qwen3-4B</b><br><span style="font-size: 12px; color: #858383;">Alibaba</span></td><td>Open-Source</td><td>893.80</td><td>39.50</td><td>2,263.8</td></tr>
              <tr><td>9</td><td style="text-align: left; padding-left: 10px;"><b>Qwen3-4B (non-thinking)</b><br><span style="font-size: 12px; color: #858383;">Alibaba</span></td><td>Open-Source</td><td>893.80</td><td>39.50</td><td>2,263.8</td></tr>
              <tr><td>10</td><td style="text-align: left; padding-left: 10px;"><b>o3</b><br><span style="font-size: 12px; color: #858383;">OpenAI</span></td><td>Commercial</td><td>2,335.24</td><td>93.50</td><td>2,497.6</td></tr>
              <tr><td>11</td><td style="text-align: left; padding-left: 10px;"><b>Qwen3-8B (non-thinking)</b><br><span style="font-size: 12px; color: #858383;">Alibaba</span></td><td>Open-Source</td><td>1,073.26</td><td>41.50</td><td>2,586.2</td></tr>
              <!-- <tr><td>12</td><td style="text-align: left; padding-left: 10px;"><b>Sky-T1-7B</b><br><span style="font-size: 12px; color: #858383;">Skywork</span></td><td>Open-Source</td><td>1,014.21</td><td>25.50</td><td>3,988.3</td></tr> -->
              <tr><td>13</td><td style="text-align: left; padding-left: 10px;"><b>Qwen3-30B-A3B-Thinking-2507</b><br><span style="font-size: 12px; color: #858383;">Alibaba</span></td><td>Open-Source</td><td>4,846.07</td><td>85.50</td><td>5,671.6</td></tr>
              <tr><td>14</td><td style="text-align: left; padding-left: 10px;"><b>Qwen3-235B-A22B-Thinking-2507</b><br><span style="font-size: 12px; color: #858383;">Alibaba</span></td><td>Open-Source</td><td>5,927.84</td><td>92.00</td><td>6,443.3</td></tr>
              <tr><td>15</td><td style="text-align: left; padding-left: 10px;"><b>Qwen3-32B (thinking)</b><br><span style="font-size: 12px; color: #858383;">Alibaba</span></td><td>Open-Source</td><td>6,135.86</td><td>85.50</td><td>7,179.0</td></tr>
              <tr><td>16</td><td style="text-align: left; padding-left: 10px;"><b>Qwen3-235B-A22B (thinking)</b><br><span style="font-size: 12px; color: #858383;">Alibaba</span></td><td>Open-Source</td><td>6,545.30</td><td>85.00</td><td>7,700.4</td></tr>
              <tr><td>17</td><td style="text-align: left; padding-left: 10px;"><b>gemini-3-pro-preview</b><br><span style="font-size: 12px; color: #858383;">Google</span></td><td>Commercial</td><td>7,523.07</td><td>95.00</td><td>7,929.5</td></tr>
              <tr><td>18</td><td style="text-align: left; padding-left: 10px;"><b>AReaL-boba-2-32B</b><br><span style="font-size: 12px; color: #858383;">inclusionAI</span></td><td>Open-Source</td><td>6,901.34</td><td>85.00</td><td>8,119.2</td></tr>
              <tr><td>19</td><td style="text-align: left; padding-left: 10px;"><b>Qwen3-30B-A3B (thinking)</b><br><span style="font-size: 12px; color: #858383;">Alibaba</span></td><td>Open-Source</td><td>6,412.52</td><td>76.50</td><td>8,388.9</td></tr>
              <tr><td>20</td><td style="text-align: left; padding-left: 10px;"><b>Qwen3-14B (thinking)</b><br><span style="font-size: 12px; color: #858383;">Alibaba</span></td><td>Open-Source</td><td>6,850.90</td><td>77.00</td><td>8,897.3</td></tr>
              <tr><td>21</td><td style="text-align: left; padding-left: 10px;"><b>AReal-boba-2-14B</b><br><span style="font-size: 12px; color: #858383;">inclusionAI</span></td><td>Open-Source</td><td>7,519.10</td><td>79.50</td><td>9,461.4</td></tr>
              <tr><td>22</td><td style="text-align: left; padding-left: 10px;"><b>AceReason-Nemotron-7B</b><br><span style="font-size: 12px; color: #858383;">NVIDIA</span></td><td>Open-Source</td><td>7,082.74</td><td>67.50</td><td>10,419.6</td></tr>
              <tr><td>23</td><td style="text-align: left; padding-left: 10px;"><b>AceReason-Nemotron-14B</b><br><span style="font-size: 12px; color: #858383;">NVIDIA</span></td><td>Open-Source</td><td>8,515.95</td><td>76.50</td><td>11,128.7</td></tr>
              <tr><td>24</td><td style="text-align: left; padding-left: 10px;"><b>gemini-2.5-flash</b><br><span style="font-size: 12px; color: #858383;">Google</span></td><td>Commercial</td><td>9,884.73</td><td>85.00</td><td>11,629.1</td></tr>
              <tr><td>25</td><td style="text-align: left; padding-left: 10px;"><b>gemini-2.5-pro</b><br><span style="font-size: 12px; color: #858383;">Google</span></td><td>Commercial</td><td>9,808.19</td><td>79.00</td><td>12,417.9</td></tr>
              <tr><td>26</td><td style="text-align: left; padding-left: 10px;"><b>AReal-boba-2-8B</b><br><span style="font-size: 12px; color: #858383;">inclusionAI</span></td><td>Open-Source</td><td>10,521.25</td><td>70.50</td><td>14,959.2</td></tr>
              <tr><td>27</td><td style="text-align: left; padding-left: 10px;"><b>Qwen3-8B (thinking)</b><br><span style="font-size: 12px; color: #858383;">Alibaba</span></td><td>Open-Source</td><td>10,637.60</td><td>65.50</td><td>16,251.0</td></tr>
              <tr><td>28</td><td style="text-align: left; padding-left: 10px;"><b>Qwen3-4B (thinking)</b><br><span style="font-size: 12px; color: #858383;">Alibaba</span></td><td>Open-Source</td><td>13,639.89</td><td>58.00</td><td>23,517.1</td></tr>
              <!-- <tr><td>29</td><td style="text-align: left; padding-left: 10px;"><b>Sky-T1-mini</b><br><span style="font-size: 12px; color: #858383;">Skywork</span></td><td>Open-Source</td><td>15,132.72</td><td>51.00</td><td>29,672.0</td></tr> -->
              <tr><td>30</td><td style="text-align: left; padding-left: 10px;"><b>gemini-2.5-flash-lite</b><br><span style="font-size: 12px; color: #858383;">Google</span></td><td>Commercial</td><td>54,042.28</td><td>40.50</td><td>133,435.3</td></tr>
            </tbody>
          </table>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section" style="background-color: #f8fafc;">
  <div class="container">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <h2 class="title is-3">Benchmark Overview</h2>
        <div class="content">
          <p class="subtitle is-5">
            OckBench provides comprehensive evaluation across multiple dimensions
          </p>
        </div>

        <!-- Statistics Cards -->
        <div class="columns is-multiline is-centered" style="margin-top: 30px;">
          <div class="column is-one-quarter">
            <div class="metric-card">
              <div class="metric-title">Questions per Domain</div>
              <div class="metric-value">200</div>
            </div>
          </div>
          <div class="column is-one-quarter">
            <div class="metric-card">
              <div class="metric-title">Task Domains</div>
              <div class="metric-value">3</div>
            </div>
          </div>
          <div class="column is-one-quarter">
            <div class="metric-card">
              <div class="metric-title">Source Datasets</div>
              <div class="metric-value">8+</div>
            </div>
          </div>
          <div class="column is-one-quarter">
            <div class="metric-card">
              <div class="metric-title">Models Evaluated</div>
              <div class="metric-value">47</div>
            </div>
          </div>
        </div>

        <!-- Task Domains -->
        <div class="content has-text-left" style="margin-top: 40px; max-width: 800px; margin-left: auto; margin-right: auto;">
          <h3 class="title is-4 has-text-centered">Benchmark Composition</h3>
          <p style="text-align: justify;">
            OckBench aggregates tasks across three complementary reasoning domains. Rather than random sampling, we apply the <strong>Differentiation Filter</strong>: selecting problems where accuracy across models falls within 10%‚Äì90% (avoiding floor/ceiling effects) and token variance is maximized ‚Äî isolating instances that reveal intrinsic efficiency differences.
          </p>
          <ul style="margin-top: 20px;">
            <li><strong>Mathematics &amp; Reasoning:</strong> GSM8K, AIME 2024/2025, OlympiadBench, MATH500, AMO-Bench, and the mathematics subset of Humanity's Last Exam ‚Äî spanning grade-school arithmetic to competition-level number theory.</li>
            <li><strong>Software Engineering:</strong> A lightweight variant of MBPP and LiveCodeBench, assessing practical code generation and planning skills verified via unit test execution.</li>
            <li><strong>Scientific Reasoning:</strong> ScienceQA, MMLU (STEM subsets), and GPQA-Diamond, testing knowledge-constrained reasoning and concision under technical load.</li>
          </ul>
        </div>

        <!-- Evaluation Metrics -->
        <!-- <div class="content has-text-left" style="margin-top: 40px; max-width: 800px; margin-left: auto; margin-right: auto;">
          <h3 class="title is-4 has-text-centered">Evaluation Metrics</h3>
          <p style="text-align: justify; margin-bottom: 15px;">
            OckBench uses <strong>decoding token count</strong> as the core efficiency metric‚Äîa model- and hardware-agnostic measure that captures the intrinsic reasoning efficiency of models.
          </p>
          <ul>
            <li><strong>Decoding Token Count (#Tokens):</strong> Total number of tokens generated during reasoning (model-agnostic, hardware-agnostic)</li>
            <li><strong>Accuracy (%):</strong> Percentage of correctly solved problems</li>
            <li><strong>Reasoning Efficiency:</strong> Computed as #Tokens / Accuracy, measuring cost per unit of correctness</li>
          </ul>
          <p style="text-align: justify; margin-top: 15px; font-style: italic; color: #64748b;">
            By selecting questions with high variance in token consumption across models, OckBench reveals efficiency differences that traditional accuracy-only benchmarks miss.
          </p>
        </div> -->
      </div>
    </div>
  </div>
</section>


<section class="section" style="background-color: #f8fafc;">
  <div class="container">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Example Tasks</h2>
        <div class="content">
          <p class="subtitle is-5">
            Sample problems from OckBench-Math and OckBench-Coding
          </p>
          <p style="font-size: 14px; color: #64748b;">
            These examples illustrate the types of problems where token efficiency varies significantly across models.
          </p>
        </div>

        <div class="columns is-multiline" style="margin-top: 30px;">
          <!-- Math Example 1 -->
          <div class="column is-half">
            <div class="box" style="text-align: left; min-height: 220px;">
              <h4 class="title is-5" style="color: #2563eb;"><i class="fas fa-calculator"></i> Math Problem (GSM8K)</h4>
              <p><strong>Question:</strong> A store sells notebooks for $3 each. If you buy more than 10, you get a 20% discount on the total price. How much would it cost to buy 15 notebooks?</p>
              <p style="margin-top: 10px; font-size: 14px; color: #64748b;">
                <strong>Domain:</strong> Mathematics &nbsp;|&nbsp; <strong>Source:</strong> GSM8K
              </p>
              <p style="margin-top: 10px; font-size: 13px; color: #2563eb; font-style: italic;">
                Token variance: Some models use 200 tokens, others use 2,000+ for the same answer.
              </p>
            </div>
          </div>

          <!-- Math Example 2 -->
          <div class="column is-half">
            <div class="box" style="text-align: left; min-height: 220px;">
              <h4 class="title is-5" style="color: #2563eb;"><i class="fas fa-calculator"></i> Math Problem (AIME)</h4>
              <p><strong>Question:</strong> Find the number of ordered pairs (a,b) of integers such that a¬≤ + b¬≤ = 2024 and both a and b are positive.</p>
              <p style="margin-top: 10px; font-size: 14px; color: #64748b;">
                <strong>Domain:</strong> Mathematics &nbsp;|&nbsp; <strong>Source:</strong> AIME 2024
              </p>
              <p style="margin-top: 10px; font-size: 13px; color: #2563eb; font-style: italic;">
                Token variance: High variance across models due to different reasoning approaches.
              </p>
            </div>
          </div>

          <!-- Coding Example 1 -->
          <div class="column is-half">
            <div class="box" style="text-align: left; min-height: 220px;">
              <h4 class="title is-5" style="color: #2563eb;"><i class="fas fa-code"></i> Coding Problem (MBPP)</h4>
              <p><strong>Task:</strong> Write a function to find the longest common subsequence of two strings. For example, lcs("ABCDGH", "AEDFHR") should return 3 (the LCS is "ADH").</p>
              <p style="margin-top: 10px; font-size: 14px; color: #64748b;">
                <strong>Domain:</strong> Coding &nbsp;|&nbsp; <strong>Source:</strong> MBPP variant
              </p>
              <p style="margin-top: 10px; font-size: 13px; color: #2563eb; font-style: italic;">
                Token variance: Efficient models write concise code with brief explanations.
              </p>
            </div>
          </div>

          <!-- Science Example -->
          <div class="column is-half">
            <div class="box" style="text-align: left; min-height: 220px;">
              <h4 class="title is-5" style="color: #2563eb;"><i class="fas fa-atom"></i> Science Problem (GPQA-Diamond)</h4>
              <p><strong>Question:</strong> A molecule undergoes a photochemical reaction in which it absorbs a photon and transitions to an excited state. If the excited state has a lifetime of 10 ns, what is the natural linewidth (in Hz) of the corresponding spectral line?</p>
              <p style="margin-top: 10px; font-size: 14px; color: #64748b;">
                <strong>Domain:</strong> Scientific Reasoning &nbsp;|&nbsp; <strong>Source:</strong> GPQA-Diamond
              </p>
              <p style="margin-top: 10px; font-size: 13px; color: #2563eb; font-style: italic;">
                Token variance: Efficient models apply the uncertainty principle directly; verbose models re-derive it from scratch.
              </p>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>



<section class="section">
  <div class="container">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Key Findings</h2>
        <div class="content has-text-centered">
          <div style="max-width: 800px; margin: 0 auto; text-align: left;">
            <ul>
              <li><strong>5√ó latency gap at the same scale:</strong> Among 7B models, AceReason-7B uses 12,315 tokens vs DeepSeek-R1-Distill-7B's 41,415 ‚Äî a 3.4√ó token gap translating to a 5.0√ó end-to-end latency difference, despite identical parameter counts.</li>
              <li><strong>Open-source accuracy ‚âà commercial, but efficiency lags:</strong> Kimi-K2-Thinking matches GPT-5-mini-high in accuracy (52.5% vs 52.0%) but consumes 43% more tokens (41,746 vs 29,297). Open-source models have closed the capability gap but trail significantly in per-token intelligence.</li>
              <li><strong>The Overthinking Tax:</strong> In the Qwen3 family, larger models are paradoxically <em>more</em> token-efficient ‚Äî Qwen3-32B-Thinking uses 19,098 tokens at 31.0% accuracy, while Qwen3-4B-Thinking burns 27,238 tokens at just 22.0%. Smaller models compensate for lower capacity with verbose, inefficient reasoning chains.</li>
              <li><strong>Cheaper per-token ‚â† cheaper per-query:</strong> DeepSeek-R1-Distill-7B generates 3.13√ó more tokens than 14B (41,415 vs 13,211) yet achieves lower accuracy (14.5% vs 15.0%). Despite costing 50% less per token, the 7B model is 57% more expensive per query in practice.</li>
              <li><strong>Gemini 3 Pro leads the frontier:</strong> Top OckScore of 70.09 with 75.5% accuracy at 24,765 avg tokens. Gemini 3 Pro resolves complex reasoning paths more succinctly than Gemini 3 Flash (36,212 tokens, OckScore 64.35), demonstrating that efficiency and accuracy are co-optimized at the frontier.</li>
              <li><strong>Frontier models are rapidly converging:</strong> Comparing successive model generations reveals simultaneous improvement in both accuracy and token efficiency ‚Äî validating Per-Token Intelligence as the primary next optimization objective for the community.</li>
            </ul>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section" style="background-color: #f8fafc;">
  <div class="container">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Citation</h2>
        <div class="content">
          <p class="subtitle is-5">
            If you find OckBench useful for your research, please cite our work
          </p>
        </div>
        <div class="box" style="background-color: #ffffff; text-align: left; max-width: 700px; margin: 20px auto;">
          <pre style="background-color: #f8fafc; padding: 20px; border-radius: 5px; overflow-x: auto; margin: 0;"><code>@article{du2025ockbench,
  title={OckBench: Measuring the Efficiency of LLM Reasoning},
  author={Du, Zheng and Kang, Hao and Han, Song and Krishna, Tushar and Zhu, Ligeng},
  journal={arXiv preprint arXiv:2511.05722},
  year={2025}
}</code></pre>
        </div>
      </div>
    </div>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <p>
        <strong>OckBench</strong> - Evaluating Accuracy and Efficiency in LLM Reasoning
      </p>
      <p style="font-size: 14px; color: #64748b; margin-top: 20px;">
        This website is adapted from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>, licensed under a <a href="https://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
      </p>
    </div>
  </div>
</footer>

<script>
  // Navbar burger toggle
  document.addEventListener('DOMContentLoaded', () => {
    const $navbarBurgers = Array.prototype.slice.call(document.querySelectorAll('.navbar-burger'), 0);
    if ($navbarBurgers.length > 0) {
      $navbarBurgers.forEach( el => {
        el.addEventListener('click', () => {
          const target = el.dataset.target;
          const $target = document.getElementById(target);
          el.classList.toggle('is-active');
          $target.classList.toggle('is-active');
        });
      });
    }
  });

  // Tab switching for leaderboard
  document.addEventListener('DOMContentLoaded', () => {
    const tabs = document.querySelectorAll('.tabs li');
    const mathTable = document.getElementById('math-table');
    const codingTable = document.getElementById('coding-table');
    
    tabs.forEach(tab => {
      tab.addEventListener('click', (e) => {
        e.preventDefault();
        
        // Remove active class from all tabs
        tabs.forEach(t => t.classList.remove('is-active'));
        
        // Add active class to clicked tab
        tab.classList.add('is-active');
        
        // Show/hide tables
        const tabType = tab.getAttribute('data-tab');
        if (tabType === 'math') {
          mathTable.style.display = 'block';
          codingTable.style.display = 'none';
        } else if (tabType === 'coding') {
          mathTable.style.display = 'none';
          codingTable.style.display = 'block';
        }
      });
    });
  });

  // Update row numbers on sort for both tables
  document.addEventListener("DOMContentLoaded", function() {
    updateRowNumbers('results-math');
    updateRowNumbers('results-coding');
    
    const mathTable = document.querySelector("#results-math");
    const codingTable = document.querySelector("#results-coding");
    
    if (mathTable) {
      mathTable.addEventListener("click", function() {
        setTimeout(() => updateRowNumbers('results-math'), 100);
      });
    }
    
    if (codingTable) {
      codingTable.addEventListener("click", function() {
        setTimeout(() => updateRowNumbers('results-coding'), 100);
      });
    }
  });

  function updateRowNumbers(tableId) {
    const rows = document.querySelectorAll(`#${tableId} tbody tr`);
    rows.forEach((row, index) => {
      row.querySelector("td").innerText = index + 1;
    });
  }
</script>

</body>
</html>

